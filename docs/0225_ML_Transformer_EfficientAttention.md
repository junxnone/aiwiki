---
Title | ML Transformer EfficientAttention
-- | --
Created @ | `2021-02-23T02:47:17Z`
Last Modify @| `2022-12-24T15:52:09Z`
Labels | ``
Edit @| [here](https://github.com/junxnone/aiwiki/issues/225)

---
# Efficient Attention

## Reference
- [Efficient Attention](https://github.com/Separius/awesome-fast-attention)
- 2020-09 Efficient Transformers: A Survey [[Paper](https://arxiv.org/abs/2009.06732)] [[Note](https://github.com/junxnone/tech-io/issues/934)]
- [Transformers大家族——Efficient Transformers: A Survey](https://zhuanlan.zhihu.com/p/263031249)

## Brief
- Efficient Transformer [**打算解决的问题**]
  - 减小内存占用
  - 减少计算量
  - 增加长序列数据的处理能力
- Dense Attention & Sparse Attention

Name | Description
-- | --
Reformer
Longformer
Linformer
Performer
Linear Transformers
Big Bird
