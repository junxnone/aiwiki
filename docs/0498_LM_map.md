---
Title | LM map
-- | --
Created @ | `2025-02-06T07:39:00Z`
Updated @| `2025-02-06T07:39:00Z`
Labels | ``
Edit @| [here](https://github.com/junxnone/aiwiki/issues/498)

---

# 大模型分布图



```markmap

#  大模型相关公司

## 国外

### OpenAI

1. **GPT-1**：2018年发布，是OpenAI开发的首个GPT系列模型，基于Transformer架构，在800万个网页数据集上训练，能够生成类似人类的文本，可完成简单的问答等任务。
2. **GPT-2**：2019年发布，相比GPT-1参数规模大幅增加，达到15亿，在800万个网页数据集上进行训练，能生成更复杂、更接近人类语言的文本，具备了一定的零样本学习能力，在多种自然语言处理任务上表现更出色。
3. **GPT-3**：2020年发布，拥有1750亿参数，在超过100亿网页的数据集上训练，语言生成能力显著提升，能够生成非常自然流畅的长篇文本，可完成翻译、写作、编程等多种任务，并且在少样本学习和零样本学习场景下都有很好的表现。
4. **GPT-3.5**：在GPT-3基础上进一步优化而来，是ChatGPT背后的模型之一，相比GPT-3在性能和效率上都有所提升，生成的内容更加准确、连贯，交互能力更强。
5. **GPT-4**：2023年发布，与GPT-3.5相比，在逻辑推理、多模态理解、复杂任务处理等方面有了质的飞跃，能够处理更复杂的指令，在多种专业考试如律师资格考试、GRE等中表现出色，甚至达到人类水平。
6. **GPT-4o**：GPT-4的衍生版本，在解决特定领域问题如国际数学奥林匹克竞赛等方面有特定的优化。
7. **OpenAI o1-preview**：2024年9月12日正式推出，专为解决复杂问题而设计，能够在响应前花费更多时间进行思考，并通过深入推理应对比以往模型更具挑战性的科学、编程和数学问题。


### Anthropic

1. **2023年3月**：Claude初代发布，展示出在多种任务上的能力，但在编码、数学和推理能力方面存在一定限制。
2. **2023年7月**：Claude 2发布，与初代相比，扩展了上下文窗口，从9000个tokens扩展到100,000个tokens，还增加了上传PDF和其他文档的功能，能够进行阅读、总结并辅助完成任务。
3. **2023年11月**：Claude 2.1发布，将聊天机器人可处理的tokens数量翻倍，增加到200,000个tokens的窗口，且该模型相比之前的版本更不容易产生虚假陈述。
4. **2024年3月**：Claude 3系列发布，包含Claude 3 Haiku、Claude 3 Sonnet、Claude 3 Opus三款模型，按能力升序排列。Claude 3是多模态大模型，具有强大的“视觉能力”，用户可以上传照片、图表、文档等数据并进行分析和提问。
5. **2024年6月**：Claude 3.5 Sonnet发布，在编码、多步骤工作流、图表解释和从图像中提取文本等基准测试方面表现出显著改进，还新增了能够在界面中创建代码并实时预览渲染输出的功能。
6. **2024年10月**：Claude 3.5 Haiku和升级后的Claude 3.5 Sonnet发布，同时推出“computer use”功能的公共测试版，该功能使Claude 3.5 Sonnet能够与计算机桌面环境进行交互，执行移动光标、点击按钮和输入文本等任务。


### Google

1. **2017年6月**：Transformer模型面世，Google大脑团队在神经信息处理系统大会上发表了名为“Attention Is All You Need”的论文，该论文被视为大语言模型的开山之作，奠定了后续诸多语言模型的架构基础。
2. **2018年10月**：BERT（Bidirectional Encoder Representations from Transformers）模型诞生，即“来自Transformers的双向编码表示”模型，它是双向模型，可以利用上下文来分析，效果优于当时的GPT-1。
3. **2019年10月**：T5（Transfer Text-to-Text Transformer）模型被提出，参数量达到了110亿，成为全新的NLP SOTA预训练模型。
4. **2021年1月**：Switch Transformer推出，有1.6万亿个参数，是GPT-3参数的9倍。
5. **2021年5月**：LaMDA（Language Model for Dialogue Applications）对话应用语言模型诞生，具有1370亿参数。
6. **2023年3月**：推出聊天机器人Bard，最初基于LaMDA模型。
7. **2023年4月**：Bard进行升级，采用更具性能的PaLM模型。
8. **2023年5月**：推出PaLM2，逐步加强逻辑推理和对话效果。
9. **2023年12月**：Gemini 1.0发布，这是谷歌史上最强大、最通用的模型，有Ultra、Pro和Nano三个版本。
10. **2024年2月**：推出Gemini Pro、Gemini Advanced，Bard改名为Gemini，并推出Gemini的Android和iOS应用；2月14日发布Gemini 1.5 Pro。
11. **2024年5月**：推出Gemini Pro 1.5、Gemini 1.5 Flash。
12. **2024年8月**：推出Gemini Pro 1.5（0801），性能超越ChatGPT-4。
13. **2024年**：推出Imagen2和Veo等模型，显著提升了图像和视频生成能力。

### Meta

1. **LLaMA 1**：2022年2月发布，是Meta进军开源大模型领域的开篇之作。基于Transformer架构，有7B、13B、33B、65B四种参数规模，在包含1.4万亿个Token的数据集上进行训练。
2. **LLaMA 2**：2023年7月18日发布，与微软合作推出。训练并发布了70亿、130亿和700亿个参数三种模型大小，基础模型在包含2万亿个Token的数据集上训练，还包括针对对话进行微调的LLaMA-2 Chat模型。
3. **Code Llama**：2023年8月发布，是基于Llama-2专注于代码生成的模型，共有7B、13B、34B和70B四个参数量版本。
4. **LLaMA 3**：2024年4月18日发布，最大版本参数量超过4000亿，当前发布了8B和70B参数量的两款模型版本，实现了多模态处理能力，能同时理解并生成文本、图像、音频等多种类型的数据。
5. **ImageBind**：2024年发布，是多模态AI模型，能将视觉、听觉、触觉等多种模态的信息进行融合和理解。


## 国内


1. **鹏城-百度·文心（ERNIE 3.0 Titan）**：2021年12月8日由鹏城实验室与百度联合发布，是全球首个知识增强千亿大模型。融合了海量知识图谱信息，在语言理解、知识推理等方面有出色表现，为后续文心一言的发展奠定了基础。
2. **文心一言**：2023年3月16日百度正式发布。具备强大的语言理解和生成能力，可进行自然流畅的对话，能完成知识问答、文本创作、逻辑推理等多种任务，还具有多领域知识增强的特点，广泛应用于客户服务、内容创作、教育等领域。
3. **通义千问**：2023年4月11日阿里巴巴推出。具备多轮对话、文案创作、逻辑推理、多模态理解、多语言支持等功能，注重与实际应用场景结合，致力于为用户提供高效、便捷的智能化服务。
4. **日日新sensenova**：2023年4月10日商汤科技发布。基于自主研发的深度学习框架和大规模预训练技术，具备高精度和高效率特点，在人脸识别、视频分析、无人驾驶等领域应用广泛。
5. **百川智能Baichuan**：2023年6月发布。拥有强大的语言处理能力、高度的灵活性以及广泛的应用前景，通过大规模语料库训练，能深刻理解语言的复杂性和多样性，实现自然、准确的语言交互。
6. **盘古大模型3.0**：2023年7月7日华为云推出。基于华为自主研发的盘古架构和大规模预训练技术，具备高性能和低能耗特点，在智慧交通、智慧城市、自动驾驶等领域应用广泛。
7. **混元大模型**：2023年9月腾讯发布。具备强大的语言理解和生成能力，支持多轮对话、文本创作、知识问答等多种任务，注重与腾讯生态系统整合，广泛应用于社交、游戏、内容等多个领域。
8. **科大讯飞星火**：2023年5月科大讯飞发布。具备知识增强、检索增强和对话增强的技术特色，支持跨语言、跨领域的知识理解和推理，可提供智能和个性化服务，还支持多模态交互，能处理文本、语音、图像等多种形式的输出。
9. **复旦大学MOSS**：是复旦大学自然语言处理实验室推出的对话式大型语言模型，支持中英双语和多种插件，具有开源特性，为用户提供了更灵活、更便捷的自然语言处理解决方案。
10. **字节跳动豆包**：2024年9月字节跳动推出。拥有多个模型版本，包括通用模型和轻量级模型，通用模型pro适合处理复杂任务，轻量级模型则以极致的响应速度和性价比为特点。
11. **DeepSeek-R1**：2025年1月20日发布，在数学、代码、自然语言推理等任务上的性能比肩OpenAI o1正式版，且API服务定价远低于OpenAI o1，还开源了模型权重。
12. **月之暗面Kimi k1.5**：2025年1月20日推出，在long - CoT（长链思维）模式下，其数学、代码、多模态推理能力达到长思考SOTA模型o1正式版的水平。


```
