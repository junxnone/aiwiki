---
Title | paper AnomalyAny cn
-- | --
Created @ | `2025-06-03T02:04:27Z`
Updated @| `2025-06-03T02:17:23Z`
Labels | ``
Edit @| [here](https://github.com/junxnone/aiwiki/issues/520)

---
# AnomalyAny CN
- 2024.6 **Anomaly Anything: Promptable Unseen Visual Anomaly Generation**


```
Han Sun  EPFL, Switzerland  Yunkang Cao   HUST, China   Hao Dong  ETH Zurich, Switzerland  Olga Fink  EPFL, Switzerland

{han.sun, olga.fink}@epfl.ch, cyk hust@hust.edu.cn, hao.dong@ibk.baug.ethz.ch

```

## Abstract

由于异常数据样本的稀缺，视觉异常检测（AD）面临着巨大挑战。尽管已有许多工作致力于合成异常样本，但这些合成的异常往往缺乏真实性，或者需要大量的训练数据，这限制了它们在现实场景中的应用。在这项工作中，我们提出了Anomaly Anything（AnomalyAny），这是一个新颖的框架，它利用Stable Diffusion（SD）的图像生成能力来生成多样且逼真的未知异常。通过在测试时以单个正常样本为条件，AnomalyAny能够针对任意物体类型，结合文本描述生成未知的异常。在AnomalyAny框架内，我们**提出了注意力引导的异常优化方法，以引导SD将注意力集中在生成关键的异常概念上**。此外，我们还**引入了提示引导的异常细化方法，通过融入详细的描述来进一步提升生成质量**。在MVTec AD和VisA数据集上进行的大量实验表明，AnomalyAny具备生成高质量未知异常的能力，并且在提升下游异常检测任务的性能方面效果显著。我们的演示和代码可在https://hansunhayden.github.io/AnomalyAny.github.io/ 获取。

## 引言

![Image](https://github.com/user-attachments/assets/0f4f06f4-e5ce-4eee-856d-7cbcb08e013d)

**图 1. 不同视觉异常生成方法的对比。与现有方法相比，AnomalyAny 无需训练即可生成多样且逼真的未知异常。**

视觉异常检测（AD）[5]旨在识别图像数据中偏离特征正态分布的不寻常或意外模式，这在工业检测和质量控制等领域至关重要[3]。由于异常样本罕见且难以收集，大多数现有AD方法依赖仅使用正常样本的无监督学习[12,22,32]。尽管AD领域最近取得了进展，但用于训练的异常样本稀缺仍是一个长期存在的挑战。为解决这一问题，各种研究已探索视觉异常生成，如图1所示：一些方法[33,35]通过从其他数据集中的自然图案或图像本身裁剪粘贴随机图案来增强正常样本，虽能生成多样化异常样本且无需训练即可应用于未知物体，但样本真实性不足；另一种利用生成模型[17]的方法虽能产出更逼真图像，却需要充足且具代表性的正常与异常样本进行训练——这对AD任务而言通常难以实现。  

鉴于异常的稀有性和可变性，收集代表性异常样本本身就极为困难，而工业场景中产品变体与配置的多样性更导致代表性正常样本匮乏[18]，双重限制加剧了两类样本的短缺。这使得生成模型在数据有限的现实应用中适用性较差，且易受少量训练样本的偏差影响。

鉴于现有视觉异常生成方法的局限性，我们旨在利用最少的正常数据（无需任何异常样本）生成多样且逼真的未知异常。这一目标促使我们探索 Stable Diffusion（SD）[27]—— 一种潜在文本到图像扩散模型，其以跨多种领域生成多样化图像而闻名。尽管 SD 展现出令人印象深刻的图像生成能力，但其并非专门为视觉异常生成设计。因此，当直接用于异常生成时，SD 可能会产生偏离预期正态分布的图像，无法准确呈现真实异常模式（图 3（b））。先前方法 [17,35] 建议在可用正常或异常样本上微调 SD，但这种方法在数据稀缺场景中受到限制，且可能削弱 SD 对未知数据和异常类型的泛化能力。


在这项工作中，我们提出了Anomaly Anything（AnomalyAny）框架，用于生成逼真且多样化的未知视觉异常。我们利用Stable Diffusion（SD）模型结合异常文本描述来生成未知视觉异常，这些文本描述可手动定义，或通过GPT-4[24]以物体类别为输入自动获取。不同于在正常数据上微调SD模型，我们引入了**测试时正常样本条件化**方法——通过单个正常样本引导生成过程。该方法保留了SD的多样性和泛化能力，使其能够针对新数据和新型异常类型生成异常样本。仅需一个模型，我们就能根据任意异常描述为任何新物体生成逼真且多样的异常样本。  

我们发现，原始SD模型难以生成真实异常样本，主要受两个固有挑战制约：其一，SD训练数据中异常样本相对稀缺；其二，与常见物体和图案不同，异常图案通常仅占据图像的小区域，在生成过程中易被忽略。为解决这些问题，我们提出**注意力引导的异常优化方法**，通过最大化与异常标记相关的注意力值，强制模型聚焦于生成异常概念。为进一步引导和细化生成结果，我们还提出**提示引导的异常细化方法**，利用更详细的异常描述作为额外语义指导。我们的主要贡献包括：
