-----

| Title     | LM map                                                |
| --------- | ----------------------------------------------------- |
| Created @ | `2025-02-06T07:39:00Z`                                |
| Updated @ | `2025-02-06T07:55:48Z`                                |
| Labels    | \`\`                                                  |
| Edit @    | [here](https://github.com/junxnone/aiwiki/issues/498) |

-----

# 大模型分布图

``` markmap

---
title: 大模型
markmap:
  initialExpandLevel: 4
---

#  大模型

## 国外

### OpenAI

- **GPT-1**
    - **发布时间**：2018年6月。
    - **特点**：开创了基于Transformer架构的语言模型先河，有1.17亿参数，采用无监督预训练和有监督微调的两阶段训练方法。
- **GPT-2**
    - **发布时间**：2019年2月。
    - **特点**：具有15亿参数，在GPT-1基础上加深网络结构，扩大模型规模，能生成连贯且有逻辑的长文本，训练数据来源更广泛，涵盖大量网页文本等，最初以多语言版本发布，展示了语言模型在零样本学习方面的潜力。
- **GPT-3**
    - **发布时间**：2020年5月。
    - **特点**：参数量达1750亿，采用了海量数据进行训练，具有强大的语言生成能力，在多种自然语言处理任务上表现出色，无需大量微调就能在很多任务中取得较好效果，能根据少量示例学习并完成新任务，即具备“少样本学习”甚至“零样本学习”能力。
- **GPT-3.5**
    - **发布时间**：2022年。
    - **特点**：ChatGPT背后的模型，在GPT-3基础上进行优化和改进，进一步提升了语言理解和生成能力，在对话场景中表现更加自然流畅，对各种问题的回答准确性和合理性有所增强。
- **GPT-4**
    - **发布时间**：2023年3月。
    - **特点**：相比GPT-3.5有显著提升，在语言理解、推理、数学、编程等多个领域性能大幅增强，具有更强的上下文理解能力和多模态处理能力，可接受图像输入并进行相关处理和回答，实现了原型AGI，智商（IQ）为48。
- **GPT-4 Turbo**
    - **发布时间**：2024年1月。
    - **特点**：OpenAI推出的GPT-4更新版本，改善了模型“变懒”的问题，生成代码能力更强，且OpenAI预告将推出带有视觉功能的GPT-4 Turbo模型。
- **OpenAI o1**
    - **发布时间**：2024年9月。
    - **特点**：全新的推理模型系列，专为解决复杂问题而设计，能够在响应前花费更多时间进行思考，并通过深入推理应对比以往模型更具挑战性的科学、编程和数学问题，在国际数学奥林匹克竞赛等任务中表现出色。
- **Orion**
    - **计划发布时间**：2024年12月。
    - **特点**：OpenAI计划推出的下一代模型，内部被视为GPT-4的继任者，有消息称其性能可能是GPT-4的100倍，OpenAI计划优先向与其密切合作的公司开放Orion的访问权限。


### Anthropic

- **Claude**
    - **发布时间**：2022年12月推出，但未对公众开放接口；2023年3月15日正式发布。
    - **特点**：Anthropic的首款正式大模型，具备基础的语言处理和对话能力，目标是开发对人类有益、诚实、无害的人工智能系统，强调安全性与合规性。
- **Claude2**
    - **发布时间**：2023年7月。
    - **特点**：相比初代，性能有所提升，能够实现更长文本的响应，在编程、数学、推理等方面有大幅提升。
- **Claude2.1**
    - **发布时间**：2023年11月22日。
    - **特点**：拥有200K的上下文窗口，进一步增强了对长文本的处理能力。
- **Claude3**
    - **发布时间**：2024年3月4日。
    - **特点**：包含Claude3 Haiku、Claude3 Sonnet和Claude3 Opus三款子模型，是多模态大模型，具有强大的“视觉能力”，用户可上传照片、图表、文档等数据进行分析和提问。其中Opus是最强大的模型，在本科和研究生水平的知识、数学和复杂任务理解方面均超过GPT-4和Gemini1.0 Ultra；Sonnet在智能程度和运行速度间实现平衡；Haiku速度较快、较紧凑，可实时响应简单查询和请求。
- **Claude3.5 Sonnet**
    - **发布时间**：2024年6月。
    - **特点**：在SWE-bench Verified上得分为49%，与原始版本相比提高近16%。
- **Claude3.5 Haiku**
    - **发布时间**：2024年10月22日。
    - **特点**：旨在提供快速响应和改进的推理能力，在保持与Claude3 Haiku相近速度和成本的同时，实现了各项能力的提升，在多项基准测试中超越了Claude3 Opus。具备编码能力，在SWE-bench Verified测试中的得分达到了40.6%，还引入了“计算机使用”功能，能模拟人类与计算机的交互方式。
- **Claude Enterprise**
    - **发布时间**：2024年9月。
    - **特点**：主要面向希望集成AI的企业设计，可代替用户在应用程序中执行一系列操作，如根据用户提供的数据集生成代码、创建销售预测等，还能够解释计算机屏幕上的内容、选择按钮、输入文本、浏览网站等。


### Google

- **Transformer**
    - **发布时间**：2017年6月。
    - **特点**：Google大脑团队在神经信息处理系统大会上发表相关论文，被视为大语言模型的开山之作，有6500万参数。
- **BERT**
    - **发布时间**：2018年10月。
    - **特点**：即“来自Transformers的双向编码表示”模型，有3亿参数，是双向模型，可利用上下文来分析。
- **T5**
    - **发布时间**：2019年10月。
    - **特点**：参数量达到了110亿，成为全新的NLP SOTA预训练模型。
- **Switch Transformer**
    - **发布时间**：2021年1月。
    - **特点**：有1.6万亿个参数，是GPT-3参数的9倍。
- **LaMDA**
    - **发布时间**：2021年5月。
    - **特点**：对话应用语言模型，具有1370亿参数。
- **PaLM**
    - **发布时间**：2022年。
    - **特点**：具有多语言、多任务处理能力，为后续的模型开发奠定了基础。
- **Bard**
    - **发布时间**：2023年2月7日。
    - **特点**：基于LaMDA的类ChatGPT产品，是谷歌推出的下一代对话AI系统。
- **Gemini 1.0**
    - **发布时间**：2023年12月7日。
    - **特点**：谷歌史上最强大、最通用的模型，为多模态模型，针对不同尺寸优化为Ultra、Pro和Nano。
- **Gemini 1.5**
    - **发布时间**：2024年2月。
    - **特点**：基于Transformer和混合专家架构，其中Gemini 1.5 Pro最高可支持10,000K（100万）token超长上下文。


### Meta

- **LLaMA 1**
    - **发布时间**：2022年2月。
    - **特点**：基于Transformer架构，旨在推动大型语言模型的小型化和平民化研究。包括7B、13B、33B、65B四种参数规模，在1.4万亿个Token的数据集上进行训练，使用旋转位置嵌入和均方根层归一化。
- **LLaMA 2**
    - **发布时间**：2023年7月18日。
    - **特点**：与微软合作推出，训练并发布了70亿、130亿和700亿个参数三种模型大小。基础模型在2万亿个Token的数据集上训练，去除了易导致数据泄露的网站内容，对权威可靠来源进行上采样。有基础模型和针对对话微调的LLaMA-2 Chat模型，运用人类反馈强化学习技术，确保与人类价值观和社会规范契合。
- **Code Llama**
    - **发布时间**：2023年8月。
    - **特点**：基于Llama-2发布的专注于代码生成的模型，共有7B、13B、34B和70B四个参数量版本。
- **LLaMA 3**
    - **发布时间**：2024年4月18日。
    - **特点**：最大版本参数量超过4000亿，发布了80亿（8B）和700亿（70B）参数量的两款模型。实现了多模态处理能力，能同时理解并生成文本、图像、音频等多种类型的数据。在单语言任务上表现卓越，在应对提示时更具多样性，推理任务能力显著提升，能更好地理解和执行指令，编写更高品质的代码。


## 国内


- **2023年**
    - **文心一言**
        - **发布时间**：2023年3月
        - **特点**：具备强大的语言理解和生成能力，可进行自然、流畅对话，提供知识问答、文本创作、逻辑推理等功能，有知识增强特点，广泛应用于客户服务、内容创作、教育等领域。
    - **通义千问**
        - **发布时间**：2023年4月
        - **特点**：拥有多轮对话、文案创作、逻辑推理、多模态理解、多语言支持等功能，注重与实际应用场景结合，为用户提供高效、便捷的智能化服务。
    - **讯飞星火认知大模型**
        - **发布时间**：2023年5月
        - **特点**：有知识增强、检索增强和对话增强技术特色，支持跨语言、跨领域的知识理解和推理，提供智能和个性化服务，支持多模态交互，能处理文本、语音、图像等多种形式输出。
    - **百川智能Baichuan**
        - **发布时间**：2023年6月
        - **特点**：拥有强大的语言处理能力、高度的灵活性以及广泛的应用前景，通过大规模语料库的训练，能深刻理解语言的复杂性和多样性，实现自然、准确的语言交互。
    - **华为盘古大模型**
        - **发布时间**：2023年7月
        - **特点**：基于华为自主研发的盘古架构和大规模预训练技术，具备高性能和低能耗特点，在智慧交通、智慧城市、自动驾驶领域有广泛应用。
    - **腾讯混元大模型**
        - **发布时间**：2023年9月
        - **特点**：具备强大的语言理解和生成能力，支持多轮对话、文本创作、知识问答等任务，注重与腾讯生态系统整合，广泛应用于社交、游戏、内容等多个领域。
- **2024年**
    - **商汤日日新**
        - **发布时间**：2024年4月
        - **特点**：基于自主研发的深度学习框架和大规模预训练技术，具备高精度和高效率特点，在人脸识别、视频分析、无人驾驶等领域有广泛应用。
    - **豆包**
        - **发布时间**：2024年9月
        - **特点**：拥有多个模型版本，通用模型pro适合处理复杂任务，轻量级模型以极致的响应速度和性价比为特点，可提供灵活选择。
    - **月之暗面Kimi**
        - **发布时间**：2024年11月发布k0-math数学模型、12月发布k1视觉思考模型
        - **特点**：在long - CoT模式下，Kimi k1.5的数学、代码、多模态推理能力达到长思考SOTA模型o1正式版的水平。
- **2025年**
    - **MiniMax海螺**
        - **发布时间**：2025年1月20日
        - **特点**：上线了语音功能，不断在多模态等方面进行能力拓展和提升。
    - **DeepSeek-R1**
        - **发布时间**：2025年1月20日
        - **特点**：在数学、代码、自然语言推理等任务上的性能比肩OpenAI o1正式版，API服务定价远低于o1，且开源了模型权重。
    - **腾讯混元3D生成大模型2.0**
        - **发布时间**：2025年1月21日
        - **特点**：支持文生、图生3D的能力，上线了3D内容AI创作平台混元3D AI创作引擎，可应用于游戏制作、电商广告、工业制造、具身智能等领域，能大幅降低3D资产制作时间成本。

```
