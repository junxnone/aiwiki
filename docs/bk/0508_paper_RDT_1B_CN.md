-----

| Title     | paper RDT-1B CN                                       |
| --------- | ----------------------------------------------------- |
| Created @ | `2025-02-18T03:20:41Z`                                |
| Updated @ | `2025-02-18T03:20:41Z`                                |
| Labels    | \`\`                                                  |
| Edit @    | [here](https://github.com/junxnone/aiwiki/issues/508) |

-----

# RDT-1B

## 摘要

双手操作在机器人领域至关重要，但由于协调两个机械臂存在固有复杂性（会导致多模态动作分布）以及训练数据稀缺，开发基础模型极具挑战性。在本文中，我们提出了机器人扩散变换器（RDT），这是一种开创性的用于双手操作的扩散基础模型。RDT基于扩散模型构建，能够有效表示多模态性，通过创新性地设计可扩展的Transformer，来处理多模态输入的异构性，并捕捉机器人数据的非线性和高频特征。为解决数据稀缺问题，我们进一步引入了物理可解释统一动作空间，它可以在保留原始动作物理意义的同时，统一各种机器人的动作表示，有助于学习可迁移的物理知识。通过这些设计，我们成功在迄今为止规模最大的多机器人数据集上对RDT进行预训练，并将其参数扩展至12亿，这使其成为基于扩散的最大规模机器人操作基础模型。最后，我们在自行创建的包含6000多个情节的多任务双手操作数据集上对RDT进行微调，以优化其操作能力。在真实机器人上进行的实验表明，RDT显著优于现有方法。它对未见物体和场景具有零样本泛化能力，能够理解并遵循语言指令，仅通过1
- 5次演示就能学习新技能，还能有效处理复杂、灵巧的任务。代码和视频请访问项目页面。

## 1 介绍

双手操作对于机器人完成现实世界的任务至关重要（埃辛格和肯普，2007年）。在实际应用中，一个有效的操作策略应能够推广到未知场景，例如从未见过的物体和场景。然而，当前的方法要么依赖特定任务的基本要素（米拉扎维·萨利希安等人，2017年；拉基塔等人，2019年；格兰嫩等人，2023a），要么局限于小规模模型、数据以及简单任务（克雷布斯等人，2021年；弗兰泽塞等人，2023年；格兰嫩等人，2023b；赵等人，2023年；格罗茨等人，2024年；刘等人，2024年），因此仅具有有限的泛化能力，在复杂任务中往往难以奏效。随着自然语言处理（阿基亚姆等人，2023年；图夫龙等人，2023年）和计算机视觉（拉德福德等人，2021年；基里洛夫等人，2023年）领域取得成功，实现可泛化行为的一个有前景的方向，是通过在大规模数据集上进行模仿学习来开发基础模型。

然而，开发一个双手操作基础模型极具挑战性。一个主要原因是，由于硬件成本高昂，特定双臂机器人可获取的数据极为稀缺（夏尔马等人，2018年；协作团队等人，2023年），这无法满足训练基础模型对数据密集型的要求。受近期单臂操作研究尝试（布罗汉等人，2023年；金等人，2024年）的启发，我们尝试先在广泛的多机器人数据集上进行预训练，然后在目标双臂机器人上收集的小数据集上进行微调。这可以帮助我们将数据规模扩大三个数量级，并有潜力从其他机器人的数据集中学习可迁移的物理知识。尽管如此，仍存在两个关键技术挑战。首先，一个具有泛化能力的基础模型在表现力和可扩展性方面都需要一个高性能的架构。双手操作中动作空间的维度是单臂操作的两倍，
这使得可行动作的分布具有更高程度的多模态性（李，2006年；贾等人，2024年），如图2b所示。因此，该模型必须具有足够的表达能力，以捕捉动作分布中的多模态性。以往的方法（赵等人，2023年；布罗汉等人，2023年；金等人，2024年）通常无法达到这一标准，导致性能不尽人意。此外，该架构需要有效地处理来自不同模态的输入，包括文本、图像和动作。它必须具有可扩展性，以便在大规模机器人数据上进行稳定训练。其次，数据异质性是由不同机器人之间物理结构和动作空间定义的差异造成的，这可能会在多机器人数据训练过程中导致负迁移，并阻碍策略的泛化（潘和杨，2009年）。现有方法要么舍弃动作空间不同的机器人，要么只保留数据中在不同机器人间结构不变的部分，这是以丢失有价值的数据为代价的（布罗汉等人，2023年；戈什等人，2023年；沙阿等人，2023a）。

在本文中，我们介绍了机器人扩散变换器（RDT），这是目前规模最大且具有强泛化能力的双手操作基础模型。RDT采用扩散变换器（DiTs）作为其可扩展的主干网络（谢等人，2020年），并针对结合视觉的语言条件双手操作进行了特殊设计。在表现力方面，RDT借助扩散模型对复杂分布进行建模的能力（索恩等人，2015年；何等人，2020年），能够从海量数据中出色地捕捉双手动作的所有模态。在可扩展性方面，我们利用Transformer主干架构，并精心设计多模态编码，以消除各种模态的异质性。机器人数据具有非线性动力学特性（德维特等人，2012年）、高频变化（戈什等人，2023年）以及固有的不稳定数值范围，这与具有时空连续性的图像和视频显著不同（陈等人，2019年；梁等人，2022年），为了刻画这些特性，我们对原始DiT结构进行了重要修改，包括多层感知器（MLP）解码、改进的归一化以及交替条件注入（其重要性见图4）。为了进一步实现RDT在异构数据上的训练，我们提出了物理可解释统一动作空间，这是一种适用于各种带夹爪机械臂机器人的统一动作格式。这种创新格式在保留原始动作物理意义的同时，减轻了不同机器人之间可能存在的冲突，有助于模型从各种机器人数据集中学习可泛化的物理知识。

通过上述设计，我们成功在迄今为止规模最大的多机器人数据集上（协作团队等人，2023年；沃克等人，2023年；方等人，2023年；库马尔等人，2024年）对RDT模型进行了预训练，并将其参数扩展至12亿，这使其成为基于扩散的规模最大的机器人操作预训练模型。为进一步提升其双手操作能力，我们在自行收集的包含6000多条轨迹的多任务双手操作数据集上对RDT进行了微调，该数据集是规模最为庞大的双手操作数据集之一。在实验中，我们将RDT与双手操作和机器人基础模型领域的强大基线模型进行了全面对比评估。结果表明，RDT取得了领先的性能，在一系列具有挑战性的任务中，成功率比基线模型提高了56%，表现超越了基线模型。特别是，RDT对未见物体、场景，指令，甚至技能具有出色的零样本和少样本（1
- 5次示例）泛化能力，
它还能够完成需要精细操作的任务，比如用操纵杆控制机器狗。最后，消融实验表明，扩散建模、大规模模型以及大量数据，都对其卓越性能有所贡献。

## 2 相关工作

**基于学习的双手操作**。学习双手操作策略面临的一个重大挑战是动作空间的高维度性，这加剧了数据稀缺问题（佐尔纳等人，2004年；史密斯等人，2012年；利奥蒂科夫等人，2016年；施泰普蒂西斯等人，2022年）以及多模态行为问题（科洛梅与托拉斯，2018年、2020年；菲格罗亚与比拉德，2017年；夏尔马等人，2018年；谢等人，2020年；弗兰泽塞等人，2023年）。一些研究开发了更具成本效益的数据收集接口（赵等人，2023年；阿尔达科等人，2024年），但它们仅限于特定的硬件配置，仍然不足以填补可泛化策略的数据缺口。其他研究尝试通过引入归纳偏差来降低数据需求，例如区分双臂以实现稳定性和功能性（格兰嫩等人，2023b）、对运动原语进行参数化（巴蒂尼察等人，2017年；阿马迪奥等人，2019年；奇特尼斯等人，2020年；弗兰泽塞等人，2023年），或者使用体素表示（格罗茨等人，2024年；刘等人，2024年）。这些方法使用了强先验或简化建模，成功缩小了动作空间，但代价是应用范围缩小，且无法表达双手行为的多模态性（皮尔斯等人，2023年）。

**机器人领域的基础模型**。基础模型通过在大规模多任务机器人数据集（协作团队等，2023年；布罗汉等，2022年；方等，2023年）上训练多任务“通用型”模型（布罗汉等，2022年、2023年；戈什等，2023年；金等，2024年），在实现可泛化行为方面展现出巨大潜力。大多数研究对大型视觉
-
语言模型进行调整，以直接预测动作（布罗汉等，2022年；德里伊斯等，2023年；布罗汉等，2023年；协作团队等，2023年；金等，2024年）。尽管这些模型在对新物体和新任务的泛化方面有所表现，但在应用于双手操作时，它们面临量化误差和行为不协调等问题（皮尔斯等，2023年），这在很大程度上是由于其对动作空间的离散化处理。为了提高精度，扩散模型已被用于连续控制（何等人，2020年；池等人，2023年；皮尔斯等人，2023年；戈什等人，2023年）。戈什等人（2023年）在Open
X -
具身（协作团队等，2023年）数据集的一个子集（25个数据集）上预训练了一个基于Transformer的扩散策略，该模型参数多达9300万。

### 3 问题表述与挑战

我们首先阐述任务并详细说明面临的挑战。为了在硬件上评估模型，我们选择ALOHA双臂机器人作为目标机器人，因为它是最具代表性的双臂机器人之一，且适合通过远程操作收集人类演示数据（赵等人，2023年；傅等人，2024年；阿尔达科等人，2024年）。图2a展示了目标机器人的示意图，它由两个带夹爪的机械臂和三个摄像头组成。请注意，我们的设置和基础模型适用于任何带夹爪的双臂机器人。

我们考虑结合视觉的语言条件双手操作这一具体任务，该任务在机器人领域至关重要，且在诸如家庭场景等现实世界场景中具有重大价值（施泰普蒂西斯等人，2020年；布罗汉等人，2022年；赵等人，2023年）。正式地讲，给定语言指令
$\\ell$ ，在 $t \\in \\mathbb{N}^{+}$ 时刻，策略会接收观测值 $o\_{t}$ ；然后生成一个动作
$a\_{t}$ ，以控制两个机器人手臂实现由 $\\ell$ 指定的目标。观测值表示为 一个三元组 $o\_{t}:=(X\_{t -
T\_{max} + 1 : t + 1}, z\_{t}, c)$ ，其中 $X\_{t - T\_{img} + 1 : t + 1} :=
(X\_{t - T\_{img} + 1}, \\ldots, X\_{t})$ 是RGB 观测历史长度为 $T\_{img}$，
$z\_t$ 是机器人的低维本体感知信息， $c$ 是控制频率。动作 $a\_t$ 通常是期望的本体感知 $z\_{t + 1}^1$
的一个子集。

双手操作中的特定任务通常包含多个要素：一项技能（例如 “拾取” 或 “擦拭” 等动词）、一个物体（例如 “瓶子” 或 “桌子”
等名词）、一个场景（即任务发生的环境），以及描述技能如何执行的一种方式（例如 “用左手拾取瓶子”
这样的状语）。面对一项新任务，实际应用中的策略需要能够泛化到训练数据中未出现过的新要素。正如第2节所讨论的，这对于以往基于规则的方法，以及基于小模型或少量数据的学习方法而言，都是具有挑战性的。

我们旨在通过模仿学习训练一个基础模型策略以实现泛化能力。然而，由于硬件成本高昂，特定双臂机器人可用的数据极为稀缺（轨迹数量少于10000条），远远达不到训练基础模型的一般要求。为解决这一问题，我们从近期单臂操作的研究进展中获得启发（戈什等人，2023年；协作团队等人，2023年；金等人，2024年），提议采用预训练和微调流程（拉德福德等人，2018年），以利用多个机器人的数据。通过这种方式，我们将数据规模扩大三个数量级。具体而言，我们首先在大规模多机器人数据集$D\_{pre}$（大多为单臂机器人数据）上对模型进行预训练，然后在目标机器人的数据集$D\_{ft}$上进行微调。我们将数据集表示为$D
= {(\\ell^{(i)}, o\_{t}^{(i)}, a\_{t}^{(i)}) | 0 ≤ t \< T^{(i)}, 1 ≤ i ≤
N}$，其中$T^{(i)}$是第$i$条轨迹的长度，$N$是轨迹的数量。此外，值得强调的是，我们的目标是利用多机器人数据来提升模型在双手操作中的泛化能力，而非为各种机器人开发一个跨实体模型。利用多机器人数据开发这样一个基础模型主要面临两个挑战：

**挑战1：如何设计一个强大的架构？**
一个具有泛化能力的基础模型需要一个强大的架构。这一要求主要涵盖两个方面。首先，该架构必须具备足够的表现力，以捕捉动作分布中的多模态性。图2b展示了一个简单示例，机器人试图抓取一个立方体。我们可以看到，与仅控制单个机械臂的单臂操作不同，完成此任务存在多种方式。在收集演示数据时，人类操作员可能会随机选择其中一种方式，这就导致收集到的动作数据具有多模态性。其次，这种架构必须具备可扩展性。作为一个基础模型，它应该能够有效地处理来自各种模态（文本、图像、动作等）的异构输入，同时具备可扩展性，以便在大规模数据集上进行稳定训练。

**挑战2：如何在异构数据上进行训练？**
在多机器人数据上进行训练带来了数据异构性这一独特挑战。不同机器人之间的物理结构和动作空间可能差异巨大。
不同机器人的物理结构和动作空间可能差异巨大。以往的尝试要么局限于动作空间相似的部分机器人（杨等人，2023年；戈什等人，2023年；金等人，2024年），要么只保留结构相同的部分输入数据（协作团队等人，2023年；杨等人，2024年），但这样做会损失大量信息。如何在这类异构数据上训练模型，在很大程度上仍未得到有效解决。

### 4 机器人扩散变换器

如图3所示，我们现在介绍机器人扩散变换器（RDT）。在4.1节中，我们将阐述扩散模型及相应架构，以应对挑战1。在4.2节中，我们提出一种物理可解释的统一动作空间，来统一各种机器人的动作空间并实现多机器人预训练，从而解决挑战2。我们还收集了一个全面的多任务双手操作数据集用于微调，以提升RDT的双手操作能力。

#### 4.1 RDT Model

扩散建模。由于存在多模态性，给定语言指令 $\\ell$ 和观测值 $o\_t$ ，可能有许多种可能的动作 $a\_t$
来推进任务。如果我们将策略建模为确定性映射 $(\\ell, o\_t) \\mapsto
a\_t$ ，并对训练数据中的 $(\\ell, o\_t, a\_t)$ 元组进行回归，那么该策略将学习动作模式的
“平均值”。这可能会导致产生分布外的动作，比如多种模式的算术平均值，而这种动作可能完全不可行（皮尔斯等人，2023年）。相反，我们选择对连续条件分布
$p(a\_t | \\ell, o\_t)$
进行建模。如第2节所讨论的，在各种方法中，扩散模型在表现力和采样质量方面都很出色，但对高维数据（如图像）进行采样时可能速度较慢。幸运的是，对于我们的设定而言，这个缺点影响不大，因为
$a\_t$ 的维度比图像低得多，只需要极少的采样开销。这使得扩散模型成为策略建模的理想选择，正如池等人（2023年）的研究所示。

然而，将扩散模型应用于机器人任务面临着独特的挑战，因为机器人物理量（即动作和本体感知）的固有特性与图像/视频数据不同。图像和视频数据虽然维度高，但往往具有一定程度的时空连续性（陈等人，2019；梁等人，2022），帧与帧之间的变化通常是渐进的。相比之下，机器人物理量具有非线性动力学特性（德维特等人，2012），并且由于碰撞、约束以及阻尼等材料特性所产生的物理相互作用，可能会出现高频变化。此外，这些物理量还具有不稳定的数值范围，这可能是由不可靠传感器产生的极端值导致的。这突出了对当前扩散模型进行调整，以有效捕捉机器人数据的不稳定性和非线性的必要性。接下来，我们将首先详细阐述扩散公式，然后介绍我们为解决这些挑战而设计的架构。

在使用扩散策略进行决策时，我们首先对一个完全随机的噪声动作 $a\_{t}^{K} \\sim N(0, I)$ 进行采样，然后执行 $K
\\in \\mathbb{N}^{+}$ 次去噪步骤，将其从 $p(a\_{t} | \\ell, o\_{t})$
分布中去噪为一个干净的动作样本 $a\_{t}^{0}$ 。

$$a\_{t}^{k - 1}=\\frac{\\sqrt{\\overline{\\alpha}^{k - 1}}
\\beta^{k}}{1 - \\overline{\\alpha}^{k}}
a\_{t}^{0}+\\frac{\\sqrt{\\alpha^{k}}(1 - \\overline{\\alpha}^{k -
1})}{1 - \\overline{\\alpha}^{k}} a\_{t}^{k}+\\sigma^{k} z, \\quad k =
K, \\ldots, 1, \\quad (1)$$

其中， ${\\alpha^{k}}*{k = 1}^{K}$ 、 ${\\sigma^{k}}*{k = 1}^{K}$
是由噪声调度预先定义的标量系数（尼科尔和达里瓦尔，2021）。这里， $\\beta^{k} :=
1 - \\alpha^{k}$ ，且 $\\overline{\\alpha}^{k - 1} := \\prod\_{i = 1}^{k -
1} \\alpha^{i}$ ，当 $k \> 1$ 时， $z \\sim N(0, I)$ ；否则，
$\\overline{\\alpha}^{k - 1} = 1$ ， $z = 0$ 。然而，在采样完成之前， $a\_{t}^{0}$
是难以处理的。我们选择使用一个带有参数 $\\theta$ 的可学习去噪网络 $f\_{\\theta}$
，从一个含噪样本中估计干净样本： $a\_{t}^{0} \\leftarrow
f\_{\\theta}(\\ell, o\_{t}, a\_{t}^{k}, k)$
。为了训练这样一个网络，我们将最小化以下去噪均方误差（MSE）：

$$\\mathcal{L}(\\theta) := MSE\\left(a\_{t}, f\_{\\theta}\\left(\\ell,
o\_{t}, \\sqrt{\\overline{\\alpha}^{k}} a\_{t}+\\sqrt{1 -
\\overline{\\alpha}^{k}} \\epsilon, k\\right)\\right), \\quad (2)$$

其中， $k \\sim Uniform({1, \\ldots, K})$ ， $\\epsilon \\sim N(0, I)$ ，并且
$(\\ell, o\_{t}, a\_{t})$ 是从我们的训练数据集中采样得到的。在本文后续内容中，我们将含噪动作输入记为
$\\tilde{a}\_{t} := \\sqrt{\\overline{\\alpha}^{k}} a\_t + \\sqrt{1 -
\\overline{\\alpha}^{k}} \\epsilon$ ，为简化起见，省略了 $k$
的上标。此外，在实际应用中，我们更倾向于一次性预测一系列动作，即一个动作块，以促进时间一致性（池等人，2023），并通过减少任务中的决策数量来缓解随时间累积的误差（赵等人，2023）。
